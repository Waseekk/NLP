{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7626ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83e5ec96",
   "metadata": {},
   "source": [
    "In this workspace, we will scrape the novel Moby Dick from the website [Project Gutenberg](https://www.gutenberg.org/) (which contains a large corpus of books) using the Python `requests` package. We'll extract words from this web data using `BeautifulSoup` before analyzing the distribution of words using the Natural Language ToolKit (`nltk`) and `Counter`.\n",
    "\n",
    "The Data Science pipeline that will be build in this workspace can be used to visualize the word frequency distributions of any novel that can found on Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebc9b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and download packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from collections import Counter\n",
    "#nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c737b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n",
      "\r\n",
      "<!DOCTYPE html\r\n",
      "   PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\r\n",
      "   \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\" >\r\n",
      "\r\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\r\n",
      "  <head>\r\n",
      "    <title>\r\n",
      "      Moby Dick; Or the Whale, by Herman Melville\r\n",
      "    </title>\r\n",
      "    <style type=\"text/css\" xml:space=\"preserve\">\r\n",
      "\r\n",
      "    body { background:#faebd0; color:black; margin-left:15%; margin-right:15%; text-align:justify }\r\n",
      "    P { text-indent: 1em; margin-top: .25em; margin-bottom: .25em; }\r\n",
      "    H1,H2,H3,H4,H5,H6 { text-align: center; margin-left: 15%; margin-right: 15%; }\r\n",
      "    hr  { width: 50%; text-align: center;}\r\n",
      "    .foot { margin-left: 20%; margin-right: 20%; text-align: justify; text-indent: -3em; font-size: 90%; }\r\n",
      "    blockquote {font-size: 100%; margin-left: 0%; margin-right: 0%;}\r\n",
      "    .mynote    {background-color: #DDE; color: #000; padding: .5em; margin-left: 10%; margin-right: 10%; font-family: sans-serif; font-size: 95%;}\r\n",
      "    .toc       { margin-left: 10%; margin-bottom: .75em;}\r\n",
      "    .toc2      { margin-left: 20%;}\r\n",
      "    div.fig    { display:block; margin:0 auto; text-align:center; }\r\n",
      "    div.middle { margin-left: 20%; margin-right: 20%; text-align: justify; }\r\n",
      "    .figleft   {float: left; margin-left: 0%; margin-right: 1%;}\r\n",
      "    .figright  {float: right; margin-right: 0%; margin-left: 1%;}\r\n",
      "    .pagenum   {display:inline; font-size: 70%; font-style:normal;\r\n",
      "               margin: 0; padding: 0; position: absolute; right: 1%;\r\n",
      "               text-align: right;}\r\n",
      "    pre        { font-family: times new roman; font-size: 100%; margin-left: 10%;}\r\n",
      "\r\n",
      "    table      {margin-left: 10%;}\r\n",
      "\r\n",
      "a:link {color:blue;\r\n",
      "\t\ttext-decoration:none}\r\n",
      "link {color:blue;\r\n",
      "\t\ttext-decoration:none}\r\n",
      "a:visited {color:blue;\r\n",
      "\t\ttext-decoration:none}\r\n",
      "a:hover {color:red}\r\n",
      "\r\n",
      "</style>\r\n",
      "  </head>\r\n",
      "  <body>\r\n",
      "<pre xml:space=\"preserve\">\r\n",
      "\r\n",
      "The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywh\n"
     ]
    }
   ],
   "source": [
    "# extracting request object\n",
    "r = requests.get('https://s3.amazonaws.com/assets.datacamp.com/production/project_147/datasets/2701-h.htm')\n",
    "\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "html = r.text\n",
    "print(html[0:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff787908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moby', 'dick', 'or', 'the', 'whale', 'by', 'herman', 'melville']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a BeautifulSoup object from the HTML\n",
    "html_soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Get the text \n",
    "moby_text = html_soup.get_text()\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "\n",
    "tokens = tokenizer.tokenize(moby_text)\n",
    "\n",
    "# words containing all tokens transformed to lowercase\n",
    "words = [token.lower() for token in tokens]\n",
    "\n",
    "# Print out the first eight words\n",
    "words[:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99d45053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the English stop words from nltk\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Print out the first eight stop words\n",
    "stop_words[:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49a566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whale', 1246), ('one', 925), ('like', 647), ('upon', 568), ('man', 527), ('ship', 519), ('ahab', 517), ('ye', 473), ('sea', 455), ('old', 452)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words_no_stop = [word for word in words if word not in stop_words]\n",
    "\n",
    "words_no_stop[:5]\n",
    "\n",
    "# Initialize a Counter object\n",
    "count = Counter(words_no_stop)\n",
    "\n",
    "# Store ten most common words and their counts as top_ten\n",
    "top_ten = count.most_common(10)\n",
    "\n",
    "# Print the top ten words and their counts\n",
    "print(top_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59d424b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

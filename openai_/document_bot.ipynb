{
  "cells": [
    {
      "source": [
        "## Building a Document Retrieval and Question Answering System Using LangChain\n",
        "\n",
        "In this project, our goal is to develop a comprehensive system for retrieving pertinent information from a collection of PDF documents and responding to questions based on the retrieved content. We will leverage LangChain, a powerful toolkit, for streamlined document processing, vectorization, and retrieval tasks. The project pipeline encompasses several key stages:\n",
        "\n",
        "### 1. Loading and Preprocessing PDF Documents\n",
        "\n",
        "We initiate the process by loading our PDF documents and performing preprocessing steps to extract relevant text chunks. This phase includes:\n",
        "\n",
        "- Parsing PDF files to extract textual content.\n",
        "- Segmenting the extracted text into manageable chunks for further processing.\n",
        "\n",
        "### 2. Vectorization and Storage\n",
        "\n",
        "Subsequently, we transform the segmented text chunks into vector representations using advanced language models such as BERT or Universal Sentence Encoder. These vectors are then stored in a dedicated vector database, such as FAISS, CHROMA, or PINECONE, to facilitate efficient retrieval.\n",
        "\n",
        "### 3. Retrieval Augmented Generation Pipeline\n",
        "\n",
        "Our pipeline incorporates a sophisticated mechanism for retrieving pertinent text chunks based on user queries and utilizing them to provide context for generating precise answers. This stage comprises the following steps:\n",
        "\n",
        "- Embedding user queries into vector representations.\n",
        "- Retrieving similar text chunks from the vector database.\n",
        "- Ranking the retrieved chunks based on their relevance to the user query.\n",
        "- Employing the retrieved chunks as contextual information for a large language model (LLM) to generate accurate answers.\n",
        "\n",
        "### 4. Question Answering Bot\n",
        "\n",
        "Lastly, we construct a question-answering bot that leverages the retrieved text chunks and user queries to generate informative answers. This phase encompasses:\n",
        "\n",
        "- Providing the user question and relevant context to the LLM.\n",
        "- Generating answers based on the supplied context.\n",
        "- Presenting the generated answers to the user in a comprehensible format.\n",
        "\n",
        "At first we will use a sigle pdf for the bot then we will use multiple pdf files for processing for the chatbot. Chatbot will generte answer based on the context of the pdf files and with the response of openai api.\n"
      ],
      "metadata": {
        "id": "bdd098e2-49c6-43df-9151-050694970b75"
      },
      "id": "bdd098e2-49c6-43df-9151-050694970b75",
      "cell_type": "markdown"
    },
    {
      "source": [
        "## Install Imports and API Keys\n",
        "\n",
        "We need to make sure our environment has the following packages:\n",
        "\n",
        "- Install `langchain`\n",
        "- Install `tiktoken`, `wikipedia`, `pypdf`, `faiss-cpu`, `pinecone-client`."
      ],
      "metadata": {
        "id": "42239f47-628c-4f50-aa9d-ee482177dd0c"
      },
      "id": "42239f47-628c-4f50-aa9d-ee482177dd0c",
      "cell_type": "markdown"
    },
    {
      "source": [
        "!pip install langchain\n",
        "!pip install tiktoken\n",
        "!pip install pypdf\n",
        "!pip install faiss-cpu\n",
        "!pip install pinecone-client"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 38260,
        "lastExecutedAt": 1708201711312,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "!pip install langchain==0.0.184\n!pip install tiktoken\n!pip install wikipedia\n!pip install pypdf\n!pip install faiss-cpu\n!pip install pinecone-client",
        "outputsMetadata": {
          "0": {
            "height": 603,
            "type": "stream"
          }
        },
        "id": "7430d0f5-7341-464e-8d2e-c1f322edeb76",
        "outputId": "8a7c1482-2777-4728-a00d-62a3f889a6dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "7430d0f5-7341-464e-8d2e-c1f322edeb76",
      "cell_type": "code",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.23)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.26)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install langchain_community\n",
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KED67IIg-NKe",
        "outputId": "92da858f-c3c5-4b25-8c28-af71ee705200"
      },
      "id": "KED67IIg-NKe",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.0.23)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.26)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain_community) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain_community) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.26->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.26->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.26->langchain_community) (2.16.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.26 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.26)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.25.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.12.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (0.1.5)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.26->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.26->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "S1Dabkzh-kIQ"
      },
      "id": "S1Dabkzh-kIQ",
      "execution_count": 129,
      "outputs": []
    },
    {
      "source": [
        "### Environments. Pinecone is a vector database that can store our data with its metadata.\n",
        "We will need:\n",
        "- OpenAI API Key.(5.00$ credit for first time use)\n",
        "- Pinecone API Key and environment.(one free project)\n",
        "\n",
        "At first, lets create the environments."
      ],
      "metadata": {
        "id": "26db4425-1415-4422-878e-fc555b2fbe0b"
      },
      "id": "26db4425-1415-4422-878e-fc555b2fbe0b",
      "cell_type": "markdown"
    },
    {
      "cell_type": "code",
      "source": [
        "# use your openai api key\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY # give the openai api key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78GBtcWTh4yq",
        "outputId": "5a465ec3-e8e2-4243-9b2b-43d3b816cd6c"
      },
      "id": "78GBtcWTh4yq",
      "execution_count": 130,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use your pinecone api key\n",
        "\n",
        "PINECONE_API_KEY = getpass()\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziIvpJc-i42q",
        "outputId": "79a1eff7-1700-480d-cff9-2a2669442cb5"
      },
      "id": "ziIvpJc-i42q",
      "execution_count": 154,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pinecone env key\n",
        "PINECONE_ENV_KEY = getpass()\n",
        "\n",
        "os.environ[\"PINECONE_ENV_KEY\"] = PINECONE_ENV_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oClAJ0hjjCuy",
        "outputId": "d32ff24b-05fd-4e1a-86d1-ecc4e002b49b"
      },
      "id": "oClAJ0hjjCuy",
      "execution_count": 132,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Basics\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# LangChain Training\n",
        "# LLM\n",
        "from langchain_community.llms import OpenAI\n",
        "\n",
        "# Document Loader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "#This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
        "# Tokenizer\n",
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "# Embedding\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# Vector DataBase\n",
        "from langchain_community.vectorstores import FAISS, Pinecone # for the vector database part -- FAISS is local and temporal, Pinecone is cloud-based and permanent.\n",
        "\n",
        "# Chains\n",
        "#from langchain.chains.question_answering import load_qa_chain\n",
        "#from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 1324,
        "lastExecutedAt": 1708201725767,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# Basics\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dotenv import load_dotenv\n\n# LangChain Training\n# LLM\nfrom langchain.llms import OpenAI\n\n# Document Loader\nfrom langchain.document_loaders import PyPDFLoader \n\n# Splitter\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter \n\n# Tokenizer\nfrom transformers import GPT2TokenizerFast  \n\n# Embedding\nfrom langchain.embeddings import OpenAIEmbeddings \n\n# Vector DataBase\nfrom langchain.vectorstores import FAISS, Pinecone # for the vector database part -- FAISS is local and temporal, Pinecone is cloud-based and permanent. \n\n# Chains\n#from langchain.chains.question_answering import load_qa_chain\n#from langchain.chains import ConversationalRetrievalChain",
        "id": "0d8360cb-c7a0-4976-8fe9-5482d14b4495"
      },
      "id": "0d8360cb-c7a0-4976-8fe9-5482d14b4495",
      "cell_type": "code",
      "execution_count": 133,
      "outputs": []
    },
    {
      "source": [
        "## LangChain library and their usages\n",
        "The LangChain library encompasses various elements to facilitate the development of intricate applications using LangChain. This module will primarily delve into the following components:\n",
        "\n",
        "**Loading and Processing Documents:**\n",
        "- Document Loaders: Tools for loading documents into the system.\n",
        "- Text Splitters: Components for breaking down text into smaller segments.\n",
        "- Chat Messages: Functionality for managing messages within the chat interface.\n",
        "\n",
        "**Interacting with Documents Using NLP:**\n",
        "- LLM Model (GPT, Llama...): Advanced language models for understanding and generating text.\n",
        "- Chains: Mechanisms for organizing and processing text chains.\n",
        "- Natural Language Retrieval: Techniques for retrieving information based on natural language queries.\n",
        "- Metadata and Indexes: Structures for storing additional information about documents.\n",
        "- Memory: Functions for retaining context and information throughout interactions.\n",
        "\n",
        "**Processes Involving Document Handling and NLP:**\n",
        "- Text Embedding (OpenAI or Open-source models): Techniques for converting text into numerical representations.\n",
        "- Vector Stores: Databases for storing and retrieving vectorized representations of text.\n"
      ],
      "metadata": {
        "id": "1f548002-dda8-4d89-9c1e-7057392c11c5"
      },
      "id": "1f548002-dda8-4d89-9c1e-7057392c11c5",
      "cell_type": "markdown"
    },
    {
      "source": [
        "### The Model - Large Language Model of our Choice\n",
        "\n",
        "Our chatbot employs a sophisticated Large Language Model (LLM) powered by artificial intelligence. This model functions by receiving textual input and generating corresponding textual responses. While the default model is ada-001, we retain the flexibility to explicitly select a model of our preference. For a comprehensive list of available models, please refer to the [documentation](https://platform.openai.com/docs/models).\n"
      ],
      "metadata": {
        "id": "46cb81ae-fe1d-4108-a050-2e66c1bbf296"
      },
      "id": "46cb81ae-fe1d-4108-a050-2e66c1bbf296",
      "cell_type": "markdown"
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "#from langchain_community.llms import OpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "sRiGYVThohmA"
      },
      "id": "sRiGYVThohmA",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Directory\n",
        "\n",
        "To begin, a directory named 'doc' has been created. This directory serves as the repository for uploading PDF files. Initially, we will focus on a single PDF file for query-response operations. Subsequently, we will expand our scope to encompass the entire directory of files in the development of our chatbot."
      ],
      "metadata": {
        "id": "DalFv-b3Be8M"
      },
      "id": "DalFv-b3Be8M"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Specify the output directory\n",
        "output_directory = \"/content/doc\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "xKCw1stYBfUR"
      },
      "id": "xKCw1stYBfUR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "#from langchain_community.llms import OpenAI\n",
        "\n",
        "#from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "chat_model = ChatOpenAI()"
      ],
      "metadata": {
        "id": "dkke7-CcG2FI"
      },
      "id": "dkke7-CcG2FI",
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the PDF\n",
        "\n",
        "To facilitate the loading of documents, we have imported PyPDFLoader and PyPDFDirectoryLoader modules. These modules enable us to efficiently load individual PDF documents and entire directories containing multiple PDFs.\n"
      ],
      "metadata": {
        "id": "U-9gtF9oBEgN"
      },
      "id": "U-9gtF9oBEgN"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "\n",
        "##We can use PyPDFLoader to load more than one PDF at once.\n",
        "pdf_loader=PyPDFLoader(\"/content/doc/codegen.pdf\")\n",
        "pdf_data=pdf_loader.load()\n",
        "\n",
        "#We can use a directory loader to load more than one PDF at once.\n",
        "dir_loader = PyPDFDirectoryLoader(\"/content/doc/\")\n",
        "pdf_directory_data = dir_loader.load()"
      ],
      "metadata": {
        "id": "-XXc_FYq6NC6"
      },
      "id": "-XXc_FYq6NC6",
      "execution_count": 135,
      "outputs": []
    },
    {
      "source": [
        "In this approach, the PyPDFLoader is used at first for loading a single pdf file then the PyPDFDirectoryLoader class is used to directly load and split PDF files from a directory.\n",
        "\n",
        "### Text Splitter\n",
        "\n",
        "In the context of building an LLM-based application, efficient handling of data is essential. This involves dividing the data into manageable portions known as data chunks, with the size of these chunks significantly impacting the quality of the chatbot.\n",
        "\n",
        "The tokenizer assumes a pivotal role in managing data chunks when working with LLMs:\n",
        "- **Tokenizer**: This tool is used for converting text data into a format that can be processed by the model.\n",
        "- The data, once tokenized, is then stored in vector stores.\n",
        "\n",
        "For the conversion of original data into tokens and subsequent splitting into data chunks, we employ the **LangChain Text Splitter**.\n",
        "\n"
      ],
      "metadata": {
        "id": "da29979d-f779-41e1-a35c-598770a03139"
      },
      "id": "da29979d-f779-41e1-a35c-598770a03139",
      "cell_type": "markdown"
    },
    {
      "source": [
        "Here, we initialize a GPT-2 tokenizer using the GPT2TokenizerFast class from the Hugging Face transformers library. This tokenizer is responsible for tokenizing the text into tokens. We set truncation=True to ensure that long sentences are truncated to fit the model's input size.\n",
        "\n",
        "The `count_tokens` function takes a string of text as input and returns the number of tokens after tokenization using the initialized tokenizer. It utilizes the `tokenizer.encode(text)` method to tokenize the text and then returns the length of the resulting list of tokens.\n"
      ],
      "metadata": {
        "id": "c72a417e-7708-4d1e-bc99-0b0ba703dbe1"
      },
      "id": "c72a417e-7708-4d1e-bc99-0b0ba703dbe1",
      "cell_type": "markdown"
    },
    {
      "source": [
        "#PDF DATA\n",
        "# 1 - Splitter\n",
        "\n",
        "\n",
        "# 3 - Create function to count tokens\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "# 4 - Define the splitter for 1 pdf\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20,\n",
        "    length_function=count_tokens\n",
        ")\n",
        "\n",
        "# 5 - Apply the .split_document command\n",
        "pdf_chunks = text_splitter.split_documents(pdf_data)\n",
        "print(\"PDF Data - Now you have {0} number of chunks.\".format(len(pdf_chunks)))\n",
        "\n",
        "# 4 - Define the splitter pdf doc\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20\n",
        ")\n",
        "\n",
        "pdf_directory_chunks = text_splitter.split_documents(pdf_directory_data)\n",
        "print(\"pdf_directory_data - Now you have {0} number of chunks.\".format(len(pdf_directory_chunks)))"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 288,
        "lastExecutedAt": 1704818288170,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "#_____________________________________________________________________PDF DATA\n# 1 - Splitter\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter \n# 2 - Tokenizer\nfrom transformers import GPT2TokenizerFast  \n \n# 3 - Create function to count tokens\ntokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n\ndef count_tokens(text: str) -> int:\n    return len(tokenizer.encode(text))\n\n# 4 - Define the splitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=200,\n    chunk_overlap=20,\n    length_function=count_tokens\n)\n\n# 5 - Apply the .split_document command\npdf_chunks = text_splitter.split_documents(pdf_data)\nprint(\"PDF Data - Now you have {0} number of chunks.\".format(len(pdf_chunks)))\n\n\n#_____________________________________________________________________HN DATA\n# 3 - We use the default len, no need to do anything.\n\n# 4 - Define the splitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=200,\n    chunk_overlap=20\n)\n\nhn_chunks = text_splitter.split_documents(hn_data)\nprint(\"Online HN - Now you have {0} number of chunks.\".format(len(hn_chunks)))",
        "outputsMetadata": {
          "0": {
            "height": 57,
            "type": "stream"
          }
        },
        "id": "bd61a742-dc5e-441a-a746-37d43012aceb",
        "outputId": "5f1afde6-eb23-48d7-debf-e5bd0d13696f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bd61a742-dc5e-441a-a746-37d43012aceb",
      "cell_type": "code",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF Data - Now you have 139 number of chunks.\n",
            "pdf_directory_data - Now you have 2161 number of chunks.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"openai-community/gpt2\")\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "# 4 - Define the splitter for 1 pdf\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20,\n",
        "    length_function=count_tokens\n",
        ")\n",
        "\n",
        "# 5 - Apply the .split_document command\n",
        "pdf_chunks = text_splitter.split_documents(pdf_data)\n",
        "print(\"PDF Data - Now you have {0} number of chunks.\".format(len(pdf_chunks)))\n",
        "\n",
        "# 4 - Define the splitter pdf doc\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20\n",
        ")\n",
        "\n",
        "pdf_directory_chunks = text_splitter.split_documents(pdf_directory_data)\n",
        "print(\"pdf_directory_data - Now you have {0} number of chunks.\".format(len(pdf_directory_chunks)))"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": null,
        "lastExecutedAt": null,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": null,
        "outputsMetadata": {
          "0": {
            "height": 57,
            "type": "stream"
          }
        },
        "id": "b4d3bcfc-64b2-48e2-ae3a-49dc9c44bd4c",
        "outputId": "c39ecd42-e1cf-4d9f-de84-95efbabcc9a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "id": "b4d3bcfc-64b2-48e2-ae3a-49dc9c44bd4c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF Data - Now you have 139 number of chunks.\n",
            "pdf_directory_data - Now you have 2161 number of chunks.\n"
          ]
        }
      ],
      "execution_count": 137
    },
    {
      "source": [
        "We can make sure that the chunking has been successful by visualizing the distribution of chunk sizes.\n",
        "Since we have selected a chunk size of 200, **the majority of our chunks should have this lenght.** However, to plot the chunk sizes, you should plot the distribution of the chunk lengths rather than the token counts."
      ],
      "metadata": {
        "id": "ad447dd1-d5a5-4b2e-91ce-ef41539ddf73"
      },
      "id": "ad447dd1-d5a5-4b2e-91ce-ef41539ddf73",
      "cell_type": "markdown"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a list of chunk sizes\n",
        "chunk_sizes_pdf = [len(chunk.page_content) for chunk in pdf_chunks]\n",
        "chunk_sizes_pdf_directory = [len(chunk.page_content) for chunk in pdf_directory_chunks]\n",
        "\n",
        "# Create DataFrames from the chunk sizes\n",
        "df_pdf = pd.DataFrame({'Chunk Size': chunk_sizes_pdf})\n",
        "df_pdf_directory = pd.DataFrame({'Chunk Size': chunk_sizes_pdf_directory})\n",
        "\n",
        "# Plot the histogram of chunk size distributions\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df_pdf['Chunk Size'], bins=40, color='skyblue', edgecolor='black')\n",
        "plt.title('Single PDF Chunk Size Distribution')\n",
        "plt.xlabel('Chunk Size')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df_pdf_directory['Chunk Size'], bins=40, color='salmon', edgecolor='black')\n",
        "plt.title('Multiple PDFs Chunk Size Distribution')\n",
        "plt.xlabel('Chunk Size')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "SgcKp0OvKsOQ",
        "outputId": "1b204193-1987-48d5-fe2b-ab63f962e561"
      },
      "id": "SgcKp0OvKsOQ",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this histogram, the x-axis represents the chunk lengths, while the y-axis represents the frequency of each length. The blue bars represent the distribution of chunk lengths for the pdf file, and the red bars represent the distribution of the whole documentary. By comparing these two distributions, we can see how the changes in parameters affected the resulting chunk lengths.\n",
        "The ideal distribution depends on the specific requirements of our text-processing task. WE might want smaller, more numerous chunks if we're dealing with fine-grained analysis or larger, fewer chunks for broader semantic analysis.\n"
      ],
      "metadata": {
        "id": "kepMcasWJL5i"
      },
      "id": "kepMcasWJL5i"
    },
    {
      "source": [
        "- **Split by pages**: If our data comes from documents organized in pages, there are methods that allow you to split data in pages to keep track of the page content. This method is specially useful when dealing with PDFs, as in the following example:"
      ],
      "metadata": {
        "id": "c149bde7-39f5-4912-83f2-fb238e4d72a7"
      },
      "id": "c149bde7-39f5-4912-83f2-fb238e4d72a7",
      "cell_type": "markdown"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Directory containing PDF files\n",
        "pdf_directory = \"/content/doc\"\n",
        "\n",
        "# Initialize an empty list to store PDF chunks\n",
        "pdf_dir_page_chunks = []\n",
        "\n",
        "# Loop through each file in the directory\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    # Check if the file is a PDF\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        # Construct the full path to the PDF file\n",
        "        pdf_file_path = os.path.join(pdf_directory, filename)\n",
        "        # Initialize PyPDFLoader with the PDF file\n",
        "        loader = PyPDFLoader(pdf_file_path)\n",
        "        # Load and split the PDF file\n",
        "        pdf_file_chunks = loader.load_and_split()\n",
        "        # Extend the list of PDF chunks with the chunks from the current file\n",
        "        pdf_dir_page_chunks.extend(pdf_file_chunks)\n",
        "\n",
        "# Output the number of chunks obtained\n",
        "print(\"Total number of PDF chunks:\", len(pdf_dir_page_chunks))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HYjDlreWbOG",
        "outputId": "ff0217f5-8dd2-43c3-cec2-e947dbc4fead"
      },
      "id": "-HYjDlreWbOG",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of PDF chunks: 141\n",
            "Total number of PDF chunks: 141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this approach, each PDF file in the directory is processed individually. For each file, the code constructs the full path to the PDF file, initializes a PyPDFLoader instance with the file, loads and splits the PDF file using loader.load_and_split(), and then extends the list of PDF chunks with the chunks obtained from the current file. Finally, the total number of PDF chunks obtained is outputted."
      ],
      "metadata": {
        "id": "IyekvobxblkM"
      },
      "id": "IyekvobxblkM"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5GVl6cNacuFS"
      },
      "id": "5GVl6cNacuFS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sample comparism between larger chunk size and smaller chunk size."
      ],
      "metadata": {
        "id": "VzqblSSqb2FM"
      },
      "id": "VzqblSSqb2FM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Model Performance**      | **Memory and Resource Usage** |\n",
        "|---------------------------|-------------------------------|\n",
        "| Larger chunk sizes may result in better performance by considering more context. | Larger chunk sizes require more memory and computational resources. |\n",
        "| Smaller chunk sizes are preferable for fine-grained analysis and resource-constrained environments. | Smaller chunk sizes help mitigate memory issues and reduce computational burden. |\n",
        "|                          |                               |\n",
        "| **Speed and Efficiency**   | **Task Specificity**          |\n",
        "|---------------------------|-------------------------------|\n",
        "| Smaller chunk sizes may lead to faster processing times and increased efficiency. | The optimal chunk size varies depending on the NLP task and data characteristics. |\n",
        "| Considerations include parallelization, distribution, and processing overhead. | Chunk size impacts tasks like NER, sentiment analysis, and document classification differently. |\n"
      ],
      "metadata": {
        "id": "ZU-URZJsN2i2"
      },
      "id": "ZU-URZJsN2i2"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7Ng1Ph6N1Q3"
      },
      "id": "M7Ng1Ph6N1Q3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MwV19bjaN1W-"
      },
      "id": "MwV19bjaN1W-",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Vector Stores\n",
        "\n",
        "Vector stores, also known as vector databases, are specialized types of databases designed to efficiently handle and manipulate high-dimensional vector data. In our case, we will store the tokenized and splitted content, e.g., the data chunks in the format that LLMs can process.\n",
        "\n",
        "There are different types of vector stores. Depending on the storage of the data, we can classify them as:\n",
        "- **Local Vector Stores**: This type of databases store the information in your local system. As an example of Local Vector Store, we will use FAISS.\n",
        "- **Online Vector Stores**: This type of databases store the information in the cloud. We will use Pinecone as out preferred option for Online Vector Stores.\n",
        "\n"
      ],
      "metadata": {
        "id": "06933573-24eb-4ba2-bf05-4410912be27e"
      },
      "id": "06933573-24eb-4ba2-bf05-4410912be27e",
      "cell_type": "markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FAISS - EXAMPLE OF LOCAL VECTOR STORE"
      ],
      "metadata": {
        "id": "_Z6hnCgcf-Ug"
      },
      "id": "_Z6hnCgcf-Ug"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We have imported the `FAISS` module from `langchain_community.vectorstores` for the vector database part. It's worth noting that FAISS is a local and temporary solution, while Pinecone is a cloud-based alternative.\n",
        "\n",
        "The code `embeddings = OpenAIEmbeddings()` initializes an embedding model using the `OpenAIEmbeddings` class.\n",
        "\n",
        "We have created two separate vector databases using FAISS: `db_FAISS_pdf` for storing documents loaded from individual PDF chunks, and `db_FAISS_dir` for storing documents from the directory of PDFs, both utilizing the initialized `embeddings` model.\n"
      ],
      "metadata": {
        "id": "JUnndoe_PHrR"
      },
      "id": "JUnndoe_PHrR"
    },
    {
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# Get embedding model\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "db_FAISS_pdf= FAISS.from_documents(pdf_chunks, embeddings)\n",
        "db_FAISS_dir= FAISS.from_documents(pdf_directory_chunks, embeddings)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 4512,
        "lastExecutedAt": 1708204683784,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "from langchain.vectorstores import FAISS  # for the vector database part -- FAISS is local and temporal, Pinecone is cloud-\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\n# Get embedding model\nembeddings = OpenAIEmbeddings()\n\n# OPTION 1: FAISS (Facebook AI Similarity Search) Local _______________________________________________________________________________________\n# Create vector database\ndb_FAISS = FAISS.from_documents(pdf_chunks, embeddings)",
        "outputsMetadata": {
          "0": {
            "height": 580,
            "type": "stream"
          },
          "1": {
            "height": 616,
            "type": "stream"
          }
        },
        "id": "b7dc17d0-275f-4376-86e1-11661a2dd1ef"
      },
      "id": "b7dc17d0-275f-4376-86e1-11661a2dd1ef",
      "cell_type": "code",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gHgdZpf1dID-"
      },
      "id": "gHgdZpf1dID-",
      "execution_count": 113,
      "outputs": []
    },
    {
      "source": [
        "### PINECONE - EXAMPLE OF ONLINE VECTOR STORE\n",
        "\n",
        "We utilized the `Pinecone` module from `langchain_pinecone` to create vector databases for storing documents. The `index_name` variable is set to \"chtbt-documents\" for both databases to identify them within the Pinecone platform.\n",
        "\n",
        "The  `db_Pinecone_pdf` creates a Pinecone vector database named  from the documents loaded from individual PDF chunks, utilizing the provided embeddings and the specified index name.\n",
        "\n",
        "Similarly, `db_Pinecone_dir` creates another Pinecone vector database named `db_Pinecone_dir` for documents from the directory of PDFs, also utilizing the embeddings and index name.\n"
      ],
      "metadata": {
        "id": "1c4faca6-6ae9-453c-90d0-b31fc75a7872"
      },
      "id": "1c4faca6-6ae9-453c-90d0-b31fc75a7872",
      "cell_type": "markdown"
    },
    {
      "source": [
        "#from langchain.vectorstores import Pinecone"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 10,
        "lastExecutedAt": 1708207034397,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "from langchain.vectorstores import Pinecone",
        "id": "05b50d9e-bd87-410b-82d2-86aa9c6804ae"
      },
      "cell_type": "code",
      "id": "05b50d9e-bd87-410b-82d2-86aa9c6804ae",
      "outputs": [],
      "execution_count": 109
    },
    {
      "source": [
        "pip install langchain_pinecone"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": null,
        "lastExecutedAt": null,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": null,
        "outputsMetadata": {
          "0": {
            "height": 603,
            "type": "stream"
          }
        },
        "id": "e0ac948b-901c-46df-b2ec-6fa811209593",
        "outputId": "08668b97-74e8-4594-9a75-8cfb5719b04e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "cell_type": "code",
      "id": "e0ac948b-901c-46df-b2ec-6fa811209593",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_pinecone in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (0.1.26)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (1.25.2)\n",
            "Requirement already satisfied: pinecone-client<4,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (3.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_pinecone) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_pinecone) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_pinecone) (0.1.5)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_pinecone) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_pinecone) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_pinecone) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain_pinecone) (8.2.3)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4,>=3->langchain_pinecone) (2024.2.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4,>=3->langchain_pinecone) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4,>=3->langchain_pinecone) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<4,>=3->langchain_pinecone) (2.0.7)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_pinecone) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_pinecone) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain_pinecone) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain_pinecone) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain_pinecone) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain_pinecone) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain_pinecone) (3.3.2)\n"
          ]
        }
      ],
      "execution_count": 149
    },
    {
      "source": [
        "import langchain_pinecone"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 58,
        "lastExecutedAt": 1708207290033,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "import langchain_pinecone",
        "id": "0fc24f90-1cbe-45d5-800b-7513f9604bb0"
      },
      "cell_type": "code",
      "id": "0fc24f90-1cbe-45d5-800b-7513f9604bb0",
      "outputs": [],
      "execution_count": 155
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import Pinecone\n",
        "\n",
        "index_name = \"chtbt-documents\"\n",
        "\n",
        "db_Pinecone_pdf= Pinecone.from_documents(pdf_chunks, embeddings, index_name=index_name)\n"
      ],
      "metadata": {
        "id": "KJw3c2m-dpt1"
      },
      "id": "KJw3c2m-dpt1",
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_Pinecone_pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPHeQEOCcHUh",
        "outputId": "dde994b0-9e70-4688-dafc-54e30748347a"
      },
      "id": "yPHeQEOCcHUh",
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_pinecone.vectorstores.Pinecone at 0x7aa9ccd898d0>"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "source": [
        "## PDF FILE Natural Language Retrieval\n",
        "We first start performing a semantic search within our Vector DataBase."
      ],
      "metadata": {
        "id": "e2e6151d-08d3-4c8f-8a7a-643c101bd701"
      },
      "id": "e2e6151d-08d3-4c8f-8a7a-643c101bd701",
      "cell_type": "markdown"
    },
    {
      "source": [
        "\n",
        "# We can define how many similarities we want to get back by defining the variable k\n",
        "query = \"Can you please tell me what is this article CODEGEN: AN OPEN LARGE LANGUAGE MODEL FOR CODE WITH MULTI-TURN PROGRAM SYNTHESIS is about?\"\n",
        "matches = db_FAISS_pdf.similarity_search(query, k=2)\n",
        "print(matches)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": null,
        "lastExecutedAt": null,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": null,
        "outputsMetadata": {
          "0": {
            "height": 257,
            "type": "stream"
          }
        },
        "id": "826da9fb-03ba-4101-b793-3b9ac3203d79",
        "outputId": "d7f5299d-ea17-44af-99df-0b9006f67084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "826da9fb-03ba-4101-b793-3b9ac3203d79",
      "cell_type": "code",
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Published as a conference paper at ICLR 2023\\nCODEGEN: ANOPEN LARGE LANGUAGE MODEL FOR\\nCODE WITH MULTI -TURN PROGRAM SYNTHESIS\\nErik Nijkamp∗, Bo Pang∗, Hiroaki Hayashi∗,\\nLifu Tu ,Huan Wang ,Yingbo Zhou ,Silvio Savarese ,Caiming Xiong\\nSalesforce Research\\nABSTRACT\\nProgram synthesis strives to generate a computer program as a solution to a given\\nproblem speciﬁcation, expressed with input-output examples or natural language\\ndescriptions. The prevalence of large language models advances the state-of-the-art\\nfor program synthesis, though limited training resources and data impede open\\naccess to such models. To democratize this, we train and release a family of large', metadata={'source': '/content/doc/codegen.pdf', 'page': 0, 'text': 'Published as a conference paper at ICLR 2023\\nCODEGEN: ANOPEN LARGE LANGUAGE MODEL FOR\\nCODE WITH MULTI -TURN PROGRAM SYNTHESIS\\nErik Nijkamp∗, Bo Pang∗, Hiroaki Hayashi∗,\\nLifu Tu ,Huan Wang ,Yingbo Zhou ,Silvio Savarese ,Caiming Xiong\\nSalesforce Research\\nABSTRACT\\nProgram synthesis strives to generate a computer program as a solution to a given\\nproblem speciﬁcation, expressed with input-output examples or natural language\\ndescriptions. The prevalence of large language models advances the state-of-the-art\\nfor program synthesis, though limited training resources and data impede open\\naccess to such models. To democratize this, we train and release a family of large'}), Document(page_content='access to such models. To democratize this, we train and release a family of large\\nlanguage models up to 16.1B parameters, called CODEGEN, on natural language\\nand programming language data, and open source the training library JAX FORMER .\\nWe show the utility of the trained model by demonstrating that it is competitive with\\nthe previous state-of-the-art on zero-shot Python code generation on HumanEval.\\nWe further investigate the multi-step paradigm for program synthesis, where a single\\nprogram is factorized into multiple prompts specifying subproblems. To this end,\\nwe construct an open benchmark, Multi-Turn Programming Benchmark (MTPB),\\nconsisting of 115 diverse problem sets that are factorized into multi-turn prompts.\\nOur analysis on MTPB shows that the same intent provided to CODEGENin multi-', metadata={'source': '/content/doc/codegen.pdf', 'page': 0, 'text': 'access to such models. To democratize this, we train and release a family of large\\nlanguage models up to 16.1B parameters, called CODEGEN, on natural language\\nand programming language data, and open source the training library JAX FORMER .\\nWe show the utility of the trained model by demonstrating that it is competitive with\\nthe previous state-of-the-art on zero-shot Python code generation on HumanEval.\\nWe further investigate the multi-step paradigm for program synthesis, where a single\\nprogram is factorized into multiple prompts specifying subproblems. To this end,\\nwe construct an open benchmark, Multi-Turn Programming Benchmark (MTPB),\\nconsisting of 115 diverse problem sets that are factorized into multi-turn prompts.\\nOur analysis on MTPB shows that the same intent provided to CODEGENin multi-'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can define how many similarities we want to get back by defining the variable k\n",
        "query = \"Can you please tell me what is this article CODEGEN: AN OPEN LARGE LANGUAGE MODEL FOR CODE WITH MULTI-TURN PROGRAM SYNTHESIS is about?\"\n",
        "matches = db_FAISS_pdf.similarity_search(query, k=3)\n",
        "display(matches[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "KkNCvI5Bd6SF",
        "outputId": "1e18b734-067d-4dbd-c806-aab0a37e7a21"
      },
      "id": "KkNCvI5Bd6SF",
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Published as a conference paper at ICLR 2023\\nCODEGEN: ANOPEN LARGE LANGUAGE MODEL FOR\\nCODE WITH MULTI -TURN PROGRAM SYNTHESIS\\nErik Nijkamp∗, Bo Pang∗, Hiroaki Hayashi∗,\\nLifu Tu ,Huan Wang ,Yingbo Zhou ,Silvio Savarese ,Caiming Xiong\\nSalesforce Research\\nABSTRACT\\nProgram synthesis strives to generate a computer program as a solution to a given\\nproblem speciﬁcation, expressed with input-output examples or natural language\\ndescriptions. The prevalence of large language models advances the state-of-the-art\\nfor program synthesis, though limited training resources and data impede open\\naccess to such models. To democratize this, we train and release a family of large'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wEWj-OEIhsxf"
      },
      "id": "wEWj-OEIhsxf"
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"Can you please tell me the findings of the artcile CODEGEN?\"\n",
        "matches2 = db_FAISS_pdf.similarity_search(query2, k=3)\n",
        "print(matches2[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm3zK3UneF1t",
        "outputId": "627e5d0d-0875-43db-e124-78ad4c8189d3"
      },
      "id": "qm3zK3UneF1t",
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Published as a conference paper at ICLR 2023\n",
            "BROADER IMPACT AND ETHICAL CONSIDERATIONS\n",
            "All variants of CODEGENare ﬁrstly pre-trained on the Pile, which includes a small portion of\n",
            "profane language. Focusing on the GitHub data that best aligns our expected use case of program\n",
            "synthesis, Gao et al. (2020) report that 0.1% of the data contained profane language, and has sentiment\n",
            "biases against gender and certain religious groups. Thus, while we did not observe in our samples,\n",
            "CODEGENmay generate such content as well. In addition to risks on natural language outputs\n",
            "(e.g., docstrings), generated programs may include vulnerabilities and safety concerns, which are not\n",
            "remedied in this work. Models should not be used in applications until being treated for these risks.\n",
            "REFERENCES\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# ONLINE - PINECONE\n",
        "\n",
        "# 1. Define our query of interest.\n",
        "query = \"Can you please tell me what is this article CODEGEN: AN OPEN LARGE LANGUAGE MODEL FOR CODE WITH MULTI-TURN PROGRAM SYNTHESIS is about?\"\n",
        "# 2. Perform the semantic search in our vector database with the similarity_search command.\n",
        "matches = db_Pinecone_pdf.similarity_search(query, k=2)\n",
        "\n",
        "# 3. Define a load_qa_chain.\n",
        "chain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n",
        "\n",
        "# 4. Execute the chain with the prompt and the matches.\n",
        "chain.run(input_documents=matches, question = query)\n"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 1946,
        "lastExecutedAt": 1708207544281,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# ONLINE - PINECONE\n\n# 1. Define our query of interest. \nquery = \"Can you please tell me all the autors of the article Attention is all you need?\"\n\n# 2. Perform the semantic search in our vector database with the similarity_search command.  \nmatches = db_Pinecone2.similarity_search(query, k=2)\n\n# 3. Define a load_qa_chain.\nchain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n\n# 4. Execute the chain with the prompt and the matches. \nchain.run(input_documents=matches, question = query)",
        "outputsMetadata": {
          "0": {
            "height": 257,
            "type": "stream"
          }
        },
        "id": "ccc9684f-f666-473f-8a48-9c8f53e413ab",
        "outputId": "acff26ff-d51d-43b8-bc92-31e58d5714b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "id": "ccc9684f-f666-473f-8a48-9c8f53e413ab",
      "cell_type": "code",
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The article \"CODEGEN: AN OPEN LARGE LANGUAGE MODEL FOR CODE WITH MULTI-TURN PROGRAM SYNTHESIS\" discusses the development and release of a family of large language models called CODEGEN, trained on natural language and programming language data. These models, with up to 16.1B parameters, aim to advance the state-of-the-art in program synthesis. The paper explores the use of these models for zero-shot Python code generation and investigates a multi-step paradigm for program synthesis, where a single program is broken down into multiple prompts. Additionally, the authors introduce a benchmark called Multi-Turn Programming Benchmark (MTPB) to evaluate the effectiveness of multi-turn prompts in program synthesis. The article emphasizes the importance of democratizing access to large language models for program synthesis.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2=\"who are the authors of this article CODEGEN: AN OPEN LARGE LANGUAGE MODEL FOR CODE WITH MULTI-TURN PROGRAM SYNTHESIS?\"\n",
        "matches2 = db_Pinecone_pdf.similarity_search(query2, k=3)\n",
        "chain.run(input_documents=matches2, question = query2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Fs4oII5bVmWc",
        "outputId": "12b738d3-d9af-4883-f5dc-26e141bac087"
      },
      "id": "Fs4oII5bVmWc",
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The authors of the article \"CODEGEN: AN OPEN LARGE LANGUAGE MODEL FOR CODE WITH MULTI-TURN PROGRAM SYNTHESIS\" are Erik Nijkamp, Bo Pang, and Hiroaki Hayashi.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "source": [
        "\n",
        "When we upload data to our vector database, there is metadata that allows us to understand where the data is coming from.\n",
        "When dealing with PDFs, the source information allows us to know what pdf and page the info is coming from."
      ],
      "metadata": {
        "id": "95ad7d06-178b-467b-979b-8976582012a7"
      },
      "id": "95ad7d06-178b-467b-979b-8976582012a7",
      "cell_type": "markdown"
    },
    {
      "source": [
        "Now it is the time to put it all together and generate a simple pipeline to query our documents using a LLM model."
      ],
      "metadata": {
        "id": "f2e5f032-6e4d-40b2-b851-ccb9c86fc097"
      },
      "id": "f2e5f032-6e4d-40b2-b851-ccb9c86fc097",
      "cell_type": "markdown"
    },
    {
      "source": [
        "\n",
        "\n",
        "# Check similarity search is working\n",
        "query = \"Who created transformers?\"\n",
        "matches = db_FAISS_dir.similarity_search(query)\n",
        "print(\"We found {0} number of similarities.\".format(len(matches)))\n",
        "for match in matches:\n",
        "    display(\"\\n\", match.page_content)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 30793,
        "lastExecutedAt": 1708209312964,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# STEP 3 - EMBEDDING AND UPLOAD DATA INTO OUR VECTORSTORE\n\n# ___________________________________________________________________________ LOCAL VERSION\n\n# 1. Create vector database with FAISS\ndb_FAISS = FAISS.from_documents(chunks, embeddings)\n\n# Check similarity search is working\nquery = \"Who created transformers?\"\nmatches = db_FAISS.similarity_search(query)\nprint(\"We found {0} number of similarities.\".format(len(matches)))\nfor match in matches:\n    print(\"\\n\", match.page_content)",
        "outputsMetadata": {
          "0": {
            "height": 603,
            "type": "stream"
          }
        },
        "id": "04a6a94c-153d-438a-978b-df189a33fa6c",
        "outputId": "049a58b4-ac26-4e8d-d0db-2beb82613c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "id": "04a6a94c-153d-438a-978b-df189a33fa6c",
      "cell_type": "code",
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We found 4 number of similarities.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Dehghani, M., Gouws, S., Vinyals, O., Uszkoreit, J., and Łukasz\\nKaiser. Universal transformers, 2019.\\nDevlin, J., Uesato, J., Bhupatiraju, S., Singh, R., rahman Mohamed,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit,\\nand Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'To the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "# Talking with our documents"
      ],
      "metadata": {
        "id": "37afb3bf-6c25-4562-b9c7-f32d17729cf9"
      },
      "id": "37afb3bf-6c25-4562-b9c7-f32d17729cf9",
      "cell_type": "markdown"
    },
    {
      "source": [
        "##  DEFINE A CHAIN AND PERFORM THE SIMILARITY SEARCH\n",
        "Generating a simple pipeline to query our documents with a load_qa_chain.\n",
        "\n",
        "1. Import the `load_qa_chain`from the langchain.chains.question_answering library.\n",
        "2. Define a prompt of interest, like: \"Can you please tell me all the autors of the article Attention is all you need?\"\n",
        "3. Define the chain.\n",
        "4. Perform a semantic search with the `.similarity_search`.\n",
        "5. Execute the chain."
      ],
      "metadata": {
        "id": "b5d54ac1-c3ff-42c3-a9c8-151548914489"
      },
      "id": "b5d54ac1-c3ff-42c3-a9c8-151548914489",
      "cell_type": "markdown"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using FAISS and openai"
      ],
      "metadata": {
        "id": "vYKt8RGsqJc_"
      },
      "id": "vYKt8RGsqJc_"
    },
    {
      "source": [
        "\n",
        "# 2. Define a prompt of interest.\n",
        "query = \"Can you please tell me  the autors of the article 'Evaluating Large Language Models Trained on Code'?\"\n",
        "\n",
        "# 3. Define the chain\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "# 4. Perform a similarity search.\n",
        "matches = db_FAISS_dir.similarity_search(query, k=1)\n",
        "\n",
        "# 5. Execute the chain to obtain a NLP based response.\n",
        "response = chain.run(input_documents = matches, question = query)\n",
        "print(response)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 1844,
        "lastExecutedAt": 1704819185918,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# 1. Import the load_qa_chain\nfrom langchain.chains.question_answering import load_qa_chain \n\n# 2. Define a prompt of interest. \nquery = \"Can you please tell me all the autors of the article Attention is all you need?\"\n\n# 3. Define the chain\nchain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n\n# 4. Perform a similarity search. \nmatches = db_FAISS.similarity_search(query, k=1)\n\n# 5. Execute the chain to obtain a NLP based response. \nresponse = chain.run(input_documents = matches, question = query)\nprint(response)",
        "outputsMetadata": {
          "0": {
            "height": 217,
            "type": "stream"
          }
        },
        "id": "85627ed4-89b0-475c-b7ea-caba04fce893",
        "outputId": "a35801ba-6136-492b-97f0-b2c277d07873",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "85627ed4-89b0-475c-b7ea-caba04fce893",
      "cell_type": "code",
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, and Henrique Ponde de Oliveira Pinto.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "Now that we already have a working pipeline to query our documents, we want to understand where our data is coming from."
      ],
      "metadata": {
        "id": "3570da7e-07ca-4dbd-a390-0f74aeabc044"
      },
      "id": "3570da7e-07ca-4dbd-a390-0f74aeabc044",
      "cell_type": "markdown"
    },
    {
      "source": [
        "# 1. Import the load_qa_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "# 2. Define a prompt of interest.\n",
        "query = \"Can you please tell me all the autors of the article 'Evaluating Large Language Models Trained on Code' is all you need?\"\n",
        "\n",
        "# 3. Define the chain\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "# 4. Perform a similarity search.\n",
        "matches = db_FAISS_dir.similarity_search(query, k=1)\n",
        "\n",
        "# 5. We define both the text and the metadata obtain from the semantic search.\n",
        "input_text = [x.page_content for x in matches]\n",
        "input_metadata= [x.metadata for x in matches]\n",
        "\n",
        "# 6. We define a metadata prompt with the metadata and ask the model to explicitily state the source.\n",
        "meta_data_enriching = \"The provided information has been extracted from {0}, please state info sources (both pdf and page) in the response\".format(input_metadata)\n",
        "\n",
        "# 7. We define an enriched query with the initial prompt and the metadata prompt.\n",
        "enriched_query = query + meta_data_enriching\n",
        "\n",
        "# 8. We execute the chain.\n",
        "response = chain.run(input_documents = matches, question = enriched_query)\n",
        "display(response)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 132434,
        "lastExecutedAt": 1708210236236,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "# 1. Import the load_qa_chain\nfrom langchain.chains.question_answering import load_qa_chain \n\n# 2. Define a prompt of interest. \nquery = \"Can you please tell me all the autors of the article Attention is all you need?\"\n\n# 3. Define the chain\nchain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n\n# 4. Perform a similarity search. \nmatches = db_FAISS.similarity_search(query, k=1)\n\n# 5. We define both the text and the metadata obtain from the semantic search.\ninput_text = [x.page_content for x in matches]\ninput_metadata= [x.metadata for x in matches]\n\n# 6. We define a metadata prompt with the metadata and ask the model to explicitily state the source. \nmeta_data_enriching = \"The provided information has been extracted from {0}, please state info sources (both pdf and page) in the response\".format(input_metadata) \n\n# 7. We define an enriched query with the initial prompt and the metadata prompt. \nenriched_query = query + meta_data_enriching\n\n# 8. We execute the chain. \nresponse = chain.run(input_documents = matches, question = enriched_query)\nprint(response)",
        "outputsMetadata": {
          "0": {
            "height": 237,
            "type": "stream"
          }
        },
        "id": "c9445c4e-6c17-4a2f-8a5e-0456873c8ac6",
        "outputId": "d9620d6e-f6b6-4fd7-ae7a-c1f23f5f2a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "id": "c9445c4e-6c17-4a2f-8a5e-0456873c8ac6",
      "cell_type": "code",
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' According to the provided information, the authors of the article \"Evaluating Large Language Models Trained on Code\" are Mark Chen*, Jerry Tworek*, Heewoo Jun*, Qiming Yuan*, and Henrique Ponde de Oliveira Pinto*. The information was extracted from the pdf file \"codex.pdf\" and the page number is 0.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "def asking_your_model(query, k):\n",
        "    # Define the chain\n",
        "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "    #Perform a similarity search.\n",
        "    matches = db_FAISS_dir.similarity_search(query, k=k)\n",
        "    #We define both the text and the metadata obtain from the semantic search.\n",
        "    input_text = [x.page_content for x in matches]\n",
        "    input_metadata= [x.metadata for x in matches]\n",
        "    #We define a metadata prompt with the metadata and ask the model to explicitily state the source.\n",
        "    meta_data_enriching = \"The provided information has been extracted from {0}, please state info sources (both pdf and page) in       the response\".format(input_metadata)\n",
        "    #We define an enriched query with the initial prompt and the metadata prompt.\n",
        "    enriched_query = query + meta_data_enriching\n",
        "    #We execute the chain.\n",
        "    response = chain.run(input_documents = matches, question = enriched_query)\n",
        "    return response\n"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 12,
        "lastExecutedAt": 1708210307954,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "def asking_your_model(query, k):\n    # Define the chain\n    chain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n    #Perform a similarity search. \n    matches = db_FAISS.similarity_search(query, k=k)\n    #We define both the text and the metadata obtain from the semantic search.\n    input_text = [x.page_content for x in matches]\n    input_metadata= [x.metadata for x in matches]\n    #We define a metadata prompt with the metadata and ask the model to explicitily state the source. \n    meta_data_enriching = \"The provided information has been extracted from {0}, please state info sources (both pdf and page) in       the response\".format(input_metadata) \n    #We define an enriched query with the initial prompt and the metadata prompt. \n    enriched_query = query + meta_data_enriching\n    #We execute the chain. \n    response = chain.run(input_documents = matches, question = enriched_query)\n    return response\n    ",
        "id": "9c4b26ec-dc92-49bc-9955-2516e8a0cca6"
      },
      "id": "9c4b26ec-dc92-49bc-9955-2516e8a0cca6",
      "cell_type": "code",
      "execution_count": 281,
      "outputs": []
    },
    {
      "source": [
        "\n",
        "# Check similarity search is working\n",
        "query = \"What is functional correctness?\"\n",
        "response = asking_your_model(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": 1337,
        "lastExecutedAt": 1708210325393,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": "from langchain.chains.question_answering import load_qa_chain \n\n# Check similarity search is working\nquery = \"What is functional correctness?\"\nresponse = asking_your_model(query, k=4)\nprint(response)",
        "outputsMetadata": {
          "0": {
            "height": 97,
            "type": "stream"
          }
        },
        "id": "64a2c499-6ef6-424d-b58d-fbd571dd0522",
        "outputId": "2b1c0584-85a2-4593-9681-181cd0263022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "id": "64a2c499-6ef6-424d-b58d-fbd571dd0522",
      "cell_type": "code",
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\" Functional correctness is a measure of how accurately code performs the intended function, often evaluated through test-driven development. It is discussed in the sources '/content/doc/codex.pdf' on pages 1 and 13.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "\n",
        "# Check similarity search is working\n",
        "query = \"What is the multi-head attention in a transformer?\"\n",
        "response = asking_your_model(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": null,
        "lastExecutedAt": null,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": null,
        "outputsMetadata": {
          "0": {
            "height": 137,
            "type": "stream"
          }
        },
        "id": "e6eb01de-7644-45a0-a88c-f290ee351640",
        "outputId": "5b82be65-b2d3-46aa-9630-a1facfa4ec3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "id": "e6eb01de-7644-45a0-a88c-f290ee351640",
      "cell_type": "code",
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Multi-head attention in a transformer allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this. This information was extracted from the document \"attentions.pdf\", page 4.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "\n",
        "# Check similarity search is working\n",
        "query = \"What are the main components of a transformer?\"\n",
        "response = asking_your_model(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": null,
        "lastExecutedAt": null,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": null,
        "outputsMetadata": {
          "0": {
            "height": 117,
            "type": "stream"
          }
        },
        "id": "0925bf69-fc5b-47d8-8f7d-322dab181ae3",
        "outputId": "5e31ff02-70fb-4ccf-f315-2972dd6c768d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "id": "0925bf69-fc5b-47d8-8f7d-322dab181ae3",
      "cell_type": "code",
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The main components of a Transformer are self-attention mechanisms. This model relies entirely on self-attention to compute representations of its input and output without using sequence-specific recurrence or convolution. \\n\\nSources:\\n- Dehghani, M., Gouws, S., Vinyals, O., Uszkoreit, J., and Łukasz Kaiser. Universal transformers, 2019.\\n- Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., rahman Mohamed,\\n- Source: /content/doc/attentions.pdf, Page 1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "\n",
        "# Check similarity search is working\n",
        "query = \"What is deep learning?\"\n",
        "response = asking_your_model(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "executionCancelledAt": null,
        "executionTime": null,
        "lastExecutedAt": null,
        "lastScheduledRunId": null,
        "lastSuccessfullyExecutedCode": null,
        "outputsMetadata": {
          "0": {
            "height": 137,
            "type": "stream"
          }
        },
        "id": "020d8c56-3973-46a3-9c63-a84cffe88078",
        "outputId": "bf8c00d2-7c25-4f00-f39a-73f4ca7f2a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "id": "020d8c56-3973-46a3-9c63-a84cffe88078",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'\\nDeep learning is a popular approach to neural program learning that has led to strong advances in the field of program learning. It is mentioned on page 12 of the codex.pdf document and on page 9 of the incoder.pdf document.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 269
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pinecone and openai"
      ],
      "metadata": {
        "id": "eQ0-O3tPnn3Q"
      },
      "id": "eQ0-O3tPnn3Q"
    },
    {
      "cell_type": "code",
      "source": [
        "db_Pinecone_dir = Pinecone.from_documents(pdf_directory_chunks, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "PdhBUt0soQS2"
      },
      "id": "PdhBUt0soQS2",
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def asking_your_model2(query, k):\n",
        "    # Define the chain\n",
        "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "    #Perform a similarity search.\n",
        "    matches = db_Pinecone_dir.similarity_search(query, k=k)\n",
        "    #We define both the text and the metadata obtain from the semantic search.\n",
        "    input_text = [x.page_content for x in matches]\n",
        "    input_metadata= [x.metadata for x in matches]\n",
        "    #We define a metadata prompt with the metadata and ask the model to explicitily state the source.\n",
        "    meta_data_enriching = \"The provided information has been extracted from {0}, please state info sources (both pdf and page) in       the response\".format(input_metadata)\n",
        "    #We define an enriched query with the initial prompt and the metadata prompt.\n",
        "    enriched_query = query + meta_data_enriching\n",
        "    #We execute the chain.\n",
        "    response = chain.run(input_documents = matches, question = enriched_query)\n",
        "    return response"
      ],
      "metadata": {
        "id": "SI5UqcupoGj3"
      },
      "id": "SI5UqcupoGj3",
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is functional correctness?\"\n",
        "response = asking_your_model2(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LT6mGVX-oP6F",
        "outputId": "dea7e6f6-1740-40d1-e4fa-65f54ecf19d2"
      },
      "id": "LT6mGVX-oP6F",
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' Functional correctness is the evaluation of code based on its ability to perform its intended function. This information is provided on page 1.0 of the codex.pdf document.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check similarity search is working\n",
        "query = \"What is the multi-head attention in a transformer?\"\n",
        "response = asking_your_model2(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CMBecfyyokNz",
        "outputId": "4b36cdc0-46c8-407f-9e10-50ba4d0de2f5"
      },
      "id": "CMBecfyyokNz",
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' The multi-head attention in a transformer is a mechanism that allows the model to attend to different parts of the input sequence simultaneously. It is used in three different ways in the transformer architecture. (Source: doc/attentions.pdf, page 4)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check similarity search is working\n",
        "query = \"What are the main components of a transformer?\"\n",
        "response = asking_your_model2(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "I8qRDhKhoy9W",
        "outputId": "ea3437d2-e598-4d20-92bd-99b7c7acc7d7"
      },
      "id": "I8qRDhKhoy9W",
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' The main components of a transformer are self-attention and an encoder-decoder structure. These are discussed in multiple sources, including the PDFs \"attentions.pdf\" (pages 1 and 7) and \"doc/attentions.pdf\" (pages 1 and 7).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check similarity search is working\n",
        "query = \"What is deep learning?\"\n",
        "response = asking_your_model2(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "k7HtBpcKo9An",
        "outputId": "42f29f98-3651-4654-bcf4-3bb6e1ba779e"
      },
      "id": "k7HtBpcKo9An",
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Deep learning is a field of study that has seen significant advancements due to the resurgence of this technology. It is an approach to program learning that utilizes two popular methods known as program induction and program synthesis. This information was extracted from page 12 of the pdf document titled \"codex.pdf.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check similarity search is working\n",
        "query = \"What is football?\"\n",
        "response = asking_your_model2(query, k=4)\n",
        "display(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CkR31BDmtOpg",
        "outputId": "10152156-2f8b-48f7-9f79-280fb2b04e5c"
      },
      "id": "CkR31BDmtOpg",
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\" I don't know, I do not see any information about football in the provided context.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Indeed, we have demonstrated how our system enables the creation of a document bot capable of querying about documents. With this approach, we not only enhance the quality of answers by leveraging the context of the documents but also provide the source of the answer.\n",
        "\n",
        "By employing FAISS as a local database and Pinecone as a cloud-based solution, which are widely utilized for large language models (LLMs), we have ensured efficient storage and retrieval of document embeddings.\n",
        "\n",
        "This system is versatile and applicable beyond articles; it can be integrated into various domains such as call centers, e-commerce platforms, or office environments for streamlined document-related tasks. A document bot has the potential to significantly simplify document-related workflows, thereby enhancing efficiency and productivity in various settings."
      ],
      "metadata": {
        "id": "KNl5o_CDtn7Y"
      },
      "id": "KNl5o_CDtn7Y"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q3KZqIJhrkCG"
      },
      "id": "Q3KZqIJhrkCG"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "editor": "DataCamp Workspace",
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}